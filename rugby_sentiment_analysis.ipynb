{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\">2024 Six Nations Drama:<br> Analyzing YouTube Reactions to Try Decision <br>Did France Deserve the Win or Was Scotland Robbed?</h1>\n",
    "\n",
    "<p style=\"text-align:center; font-size:large;\">Created By: Christopher Castor</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "The 2024 Six Nations rugby match between Scotland and France delivered a gripping and controversial moment in the final seconds, where an inconclusive last-gasp try review determined the outcome. As on-field referee Nic Berry called no-try despite potential evidence suggesting otherwise, the match concluded with France holding on to a tense victory. This pivotal decision has sparked widespread discussions and debates among rugby enthusiasts and fans.\n",
    "\n",
    "This Jupyter notebook seeks to explore and analyze public sentiment surrounding this contentious last-minute call using the comments section of the [official Six Nations YouTube highlight video](https://www.youtube.com/watch?v=Rcst-jIOQDo). The goal is to determine whether the majority of viewers agree with the no-try decision by leveraging OpenAI and sentiment analysis techniques. \n",
    "\n",
    "## Data\n",
    "Data collection was performed utilizing the Google YouTube API, which facilitated the extraction of reactions from the highlight video. This API allowed access to and retrieval of comments and likes associated with the video, offering valuable insights into the diverse reactions and opinions of the viewers. Subsequently, the comments underwent evaluation using OpenAI's API to gauge sentiment regarding the contentious last-second call.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- <a href='#1'> 1. Import Libraries</a>\n",
    "- <a href='#2'> 2. Define Functions</a>\n",
    "- <a href='#3'> 3. Retrieve and Clean Data</a>\n",
    "- <a href='#4'> 4. Determine Sentiment</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='1'>1. Import Libraries</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from collections import Counter\n",
    "\n",
    "# Import api libraries\n",
    "from googleapiclient.discovery import build\n",
    "from openai import OpenAI\n",
    "\n",
    "# Import natural language processing (nlp)\n",
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import html\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-dark')\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Load spaCy model with TextBlob capabilities\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"spacytextblob\")\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Import API Key and Video ID\n",
    "load_dotenv()\n",
    "api_key = os.getenv('API_KEY')\n",
    "video_id = os.getenv('VIDEO_ID')\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key = os.getenv('OPENAI_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='2'>2. Define Functions</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_decision(prompt):\n",
    "    '''\n",
    "    Generate a decision using OpenAI's chat model.\n",
    "\n",
    "    Parameters:\n",
    "    - prompt (str): The input prompt for the chat model.\n",
    "\n",
    "    Returns:\n",
    "    - decision (str): The generated decision based on the prompt.\n",
    "    '''\n",
    "    # Create chat completion with the given prompt\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-3.5-turbo-0125\",\n",
    "        messages=[{'role':'user', 'content':prompt}]\n",
    "    )\n",
    "\n",
    "    decision = response.choices[0].message.content\n",
    "\n",
    "    return decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decisions(comment):\n",
    "    '''\n",
    "    Generate decisions for a comment using OpenAI's chat model.\n",
    "\n",
    "    Parameters:\n",
    "    - common_prompt (str): The main prompt to include before each video reaction.\n",
    "    - comment (str): The main comment for which a decision is generated.\n",
    "\n",
    "    Returns:\n",
    "    - comment_decision (str): The generated decision and confidence for the comment.\n",
    "    '''\n",
    "    # Generate decision for the comment\n",
    "    comment_prompt = common_prompt + '\\n\\n\"' + comment + '\"'\n",
    "    comment_decision = generate_decision(comment_prompt)\n",
    "\n",
    "    return comment_decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    Clean and decode HTML entities from the input text.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The text to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "    - html.unescape(text) (str): The text after cleaning and decoding HTML entities.\n",
    "    '''\n",
    "    return html.unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_reactions(video_id, api_key):\n",
    "\t'''\n",
    "\tRetrieve comments data for a YouTube video.\n",
    "\n",
    "\tParameters:\n",
    "\t- video_id (str): The YouTube video ID.\n",
    "\t- api_key (str): The YouTube Data API key.\n",
    "\n",
    "\tReturns:\n",
    "\t- df (DataFrame): DataFrame containing comments and likes.\n",
    "\t'''\n",
    "\t# Create a list to store comments and related information\n",
    "\tcomments_data = []\n",
    "\n",
    "\t# Create YouTube resource object\n",
    "\tyoutube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "\t# Retrieve YouTube video comments\n",
    "\tvideo_response=youtube.commentThreads().list(\n",
    "\tpart='snippet',\n",
    "\tvideoId=video_id\n",
    "\t).execute()\n",
    "\n",
    "\t# Iterate through video comments\n",
    "\twhile video_response:\n",
    "\t\n",
    "\t\t# Extract information from each object\n",
    "\t\tfor item in video_response['items']:\n",
    "\t\t\n",
    "\t\t\t# Extract comment text\n",
    "\t\t\tcomment_text = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "\t\t\t\n",
    "\t\t\t# Extract number of likes for each comment\n",
    "\t\t\tlikes_count = item['snippet']['topLevelComment']['snippet']['likeCount']\n",
    "\n",
    "\t\t\t# Append information to the list\n",
    "\t\t\tcomments_data.append({'Comment': comment_text, 'Like_Count': likes_count})\n",
    "\n",
    "\t\t# Repeat for the next page if available\n",
    "\t\tif 'nextPageToken' in video_response:\n",
    "\t\t\tvideo_response = youtube.commentThreads().list(\n",
    "\t\t\t\t\tpart = 'snippet',\n",
    "\t\t\t\t\tvideoId = video_id,\n",
    "\t\t\t\t\tpageToken = video_response['nextPageToken']\n",
    "\t\t\t\t).execute()\n",
    "\t\telse:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t# Create DataFrame containing comments and related information\n",
    "\tdf = pd.DataFrame(comments_data)\n",
    "\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distribution(counts, percentages, color, title):\n",
    "    '''\n",
    "    Generate a bar plot to visualize the distribution of categories.\n",
    "\n",
    "    Parameters:\n",
    "    - counts (pd.Series): Series containing counts for each category.\n",
    "    - percentages (list): List of percentage values corresponding to each category.\n",
    "    - color (str): Color of the bars in the plot.\n",
    "    - title (str): Title of the plot.\n",
    "\n",
    "    Returns:\n",
    "    None (Displays the plot).\n",
    "    '''\n",
    "    # Create a new figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Create bars for each category with the specified color\n",
    "    bars = ax.bar(counts.index, counts, color=color)\n",
    "\n",
    "    # Add percentage labels above each bar\n",
    "    for bar, percentage in zip(bars, percentages):\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, yval + 0.05, f'{percentage: .1f}%', ha='center', va='bottom', weight='bold')\n",
    "\n",
    "    # Set the title of the plot\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', y=1.05)\n",
    "\n",
    "    # Display the plot\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_sentiment(df, col):\n",
    "    '''\n",
    "    Calculate the average sentiment score for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters: \n",
    "    - df (DataFrame): Input DataFrame containing the text data.\n",
    "    - col (str): Name of the column in the DataFrame containing the text data.\n",
    "\n",
    "    Returns:\n",
    "    - average_sentiment (float): Average sentiment score for the specified column.\n",
    "    '''\n",
    "    # Ensure the specified column exists in the DataFrame\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Column '{col}' does not exist\")\n",
    "    \n",
    "    # Initialize the VADER sentiment analyzer\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Process each text in the column\n",
    "    sentiment_scores = []\n",
    "    for text in df[col]:\n",
    "        # Tokenize the text using spaCy\n",
    "        doc = nlp(text)\n",
    "\n",
    "        # Calculate sentiment score using NLTK VADER \n",
    "        compound_score = sid.polarity_scores(text)['compound']\n",
    "        sentiment_scores.append(compound_score)\n",
    "\n",
    "    # Calculate the average sentiment score\n",
    "    average_sentiment = sum(sentiment_scores)/len(sentiment_scores)\n",
    "    return average_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_word_cloud_word(text):\n",
    "    '''\n",
    "    Tokenize and clean the input text for word cloud generation.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): Input text to be processed\n",
    "\n",
    "    Returns:\n",
    "    - cleaned_text (str): Cleaned and processed text suitable for word cloud generation.\n",
    "    '''\n",
    "    # Tokenize the input text using spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Initialize the VADER sentiment analyzer\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Extract tokens, excluding stopwords and non-alphabetic tokens\n",
    "    cleaned_tokens = [token.text.lower() for token in doc if (\n",
    "        (token.text.lower() in ['robbed']) or (\n",
    "        not token.is_stop and \n",
    "        token.is_alpha and \n",
    "        (sid.polarity_scores(token.text)['compound'] != 0))\n",
    "        )]\n",
    "    \n",
    "    # Join the cleaned tokens into a single string\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "\n",
    "    # Return the cleaned and processed text\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_cloud(comments, title, stopwords=None):\n",
    "    '''\n",
    "    Generate a word cloud from a list of comments.\n",
    "\n",
    "    Parameters:\n",
    "    - comments (list): List of text comments.\n",
    "    - title (str): Title for the word cloud plot.\n",
    "    - stopwords (set): Set of stopwords to be excluded from the word cloud.\n",
    "\n",
    "    Returns:\n",
    "    None (Displays the word cloud plot)\n",
    "    '''\n",
    "    # Clean the comments\n",
    "    cleaned_comments = [clean_text_word_cloud_word(comment) for comment in comments]\n",
    "\n",
    "    # Create a WordCloud object with specified parameters\n",
    "    if stopwords:\n",
    "        wordcloud = WordCloud(width=800, height=400, max_words=1000, background_color='white', stopwords=stopwords).generate(' '.join(cleaned_comments))\n",
    "    else:\n",
    "        wordcloud = WordCloud(width=800, height=400, max_words=1000, background_color='white').generate(' '.join(cleaned_comments))\n",
    "    \n",
    "    # Plot the word cloud\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Set the title of the plot\n",
    "    plt.title(title, fontsize=18, fontweight='bold', y=1.05)\n",
    "\n",
    "    # Return the word cloud plot\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='3'>3. Retrieve and Clean Data</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve comments and likes from the YouTube video\n",
    "reaction_df = video_reactions(video_id, api_key)\n",
    "\n",
    "# Clean text in the 'Comment' column\n",
    "reaction_df['Comment'] = reaction_df['Comment'].apply(clean_text)\n",
    "\n",
    "# Display number of comments\n",
    "print('Comments: {}'.format(len(reaction_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='4'>4. Determine Sentiment</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a common prompt to be used for generating decisions\n",
    "# common_prompt = '''\n",
    "# Scotland were denied victory by an inconclusive last-second try review as France held on to win a tense Six Nations rugby encounter. Replays suggested the ball was grounded by Sam Skinner but the on-field referee, Nic Berry, called no try and the Television Match Official (TMO), claimed to not have the evidence to conclusively prove otherwise. Fan's either agree with the referees' decision of no try, implying that the fan is happy and the ball was lost and the referees did a good job and France deservedly won ('Agree') OR fan's disagree with the decision of no try, implying that the fan is upset and the ball was grounded and touched the ground and it was a clear try and the referees did a bad job and Scotland was robbed and deserved to win ('Disagree'). Read a fan's statement below and use the criteria above to choose 'Agree' or 'Disagree' and provide a confidence level between 1-5, where 1 means you have no idea, and 5 means you are extremely confident. Separate the word and number with a colon. So your reply should be in the format, word:number.\n",
    "# '''\n",
    "common_prompt = '''\n",
    "Scotland were denied victory by an inconclusive last-second try review as France held on to win a tense Six Nations rugby encounter. Replays suggested the ball was grounded by Sam Skinner but the on-field referee, Nic Berry, called no try and the Television Match Official (TMO), claimed to not have the evidence to conclusively prove otherwise. Fan's either agree with the referees' decision of no try, implying that the fan is happy and the ball was lost and the referees did a good job and France deservedly won ('Agree') OR fan's disagree with the decision of no try, implying that the fan is upset and the ball was grounded and touched the ground and it was a clear try and the referees did a bad job and Scotland was robbed and deserved to win ('Disagree'). Read a fan's statement below and use the criteria above to choose 'Agree' or 'Disagree' and provide a confidence level between 1-5, where 1 means you have low confidence and 5 is high confidence. Separate the word and number with a colon. So your reply should be in the format, word:number.\n",
    "'''\n",
    "\n",
    "# Generate decisions for each comment\n",
    "reaction_df['OpenAI_Response'] = reaction_df['Comment'].apply(get_decisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean returned OpenAI response\n",
    "reaction_df['OpenAI_Response'] = reaction_df['OpenAI_Response'].astype(str).replace(to_replace = r'[. ]', value='', regex=True)\n",
    "\n",
    "# Split into decision and confidence\n",
    "reaction_df[['Comment_Decision','Comment_Decision_Confidence']] = reaction_df['OpenAI_Response'].str.split(':', expand=True)\n",
    "\n",
    "# Clean the decision column\n",
    "reaction_df['Comment_Decision'] = np.where(~reaction_df['Comment_Decision'].isin(['Agree','Disagree']),'Inconclusive',reaction_df['Comment_Decision'])\n",
    "\n",
    "# Clean the confidence column\n",
    "reaction_df['Comment_Decision_Confidence'] = reaction_df['Comment_Decision_Confidence'].fillna(np.NaN).astype(str).str[:1]\n",
    "reaction_df['Comment_Decision_Confidence'] = np.where(reaction_df['Comment_Decision_Confidence']=='n',1,reaction_df['Comment_Decision_Confidence']).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction_df['OpenAI_Response'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction_df['Comment_Decision'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction_df['Comment_Decision_Confidence'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction_df.sample(frac=0.2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reaction_df.loc[407][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction_df.sort_values(by='Like_Count', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agree_comment_with_most_likes = reaction_df[reaction_df['Comment_Decision']=='Agree'].reset_index(drop=True).loc[reaction_df[reaction_df['Comment_Decision']=='Agree'].reset_index(drop=True)['Like_Count'].idxmax(), 'Comment']\n",
    "disagree_comment_with_most_likes = reaction_df[reaction_df['Comment_Decision']=='Disagree'].reset_index(drop=True).loc[reaction_df[reaction_df['Comment_Decision']=='Disagree'].reset_index(drop=True)['Like_Count'].idxmax(), 'Comment']\n",
    "\n",
    "print('Agree comment with most likes: {}'.format(agree_comment_with_most_likes))\n",
    "print('Disagree comment with most likes: {}'.format(disagree_comment_with_most_likes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='5'>5. Sentiment Distribution</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distribution of YouTube comment sentiment\n",
    "comment_counts = reaction_df['Comment_Decision'].value_counts().sort_index()\n",
    "comment_percentages = (comment_counts / len(reaction_df)) * 100\n",
    "generate_distribution(comment_counts, comment_percentages, 'lightsteelblue', \"OpenAI's Assessment: YouTube Comment Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distribution of YouTube comment likes sentiment\n",
    "like_counts = reaction_df['Like_Count'].groupby(reaction_df['Comment_Decision']).sum().sort_index()\n",
    "like_percentages = (like_counts / (reaction_df['Like_Count'].groupby(reaction_df['Comment_Decision']).sum()).sum()) * 100\n",
    "generate_distribution(like_counts, like_percentages, 'cornflowerblue', \"OpenAI's Assessment: YouTube Comment Likes Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distribution of OpenAI's confidence on sentiment\n",
    "confidence_counts = reaction_df['Comment_Decision_Confidence'].value_counts().sort_index()\n",
    "confidence_percentages = (confidence_counts / len(reaction_df)) * 100\n",
    "generate_distribution(confidence_counts, confidence_percentages, 'royalblue', \"OpenAI's Confidence: YouTube Comment Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grouped bar chart showing OpenAI's assessment vs confidence\n",
    "ax = sns.countplot(data=reaction_df, x='Comment_Decision', hue='Comment_Decision_Confidence', palette=\"crest\")\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "ax.set_title(\"OpenAI's Assessment vs Confidence\", fontsize=14, fontweight='bold', y=1.05)\n",
    "ax.legend(title='Confidence')\n",
    "\n",
    "total = len(reaction_df)\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if height > 0:\n",
    "        ax.text(p.get_x() + p.get_width() / 2., height + 0.1, f'{height/total: .1%}', ha='center', va='bottom', weight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame that only has comment's with a confidence score of 3 or above\n",
    "confident_decisions = reaction_df[reaction_df['Comment_Decision_Confidence']>2].reset_index(drop=True)\n",
    "print(len(confident_decisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_sentiment_agree = round(calculate_average_sentiment(confident_decisions[confident_decisions['Comment_Decision']=='Agree'].reset_index(drop=True), 'Comment'),2)\n",
    "average_sentiment_disagree = round(calculate_average_sentiment(confident_decisions[confident_decisions['Comment_Decision']=='Disagree'].reset_index(drop=True), 'Comment'),2)\n",
    "\n",
    "print('Sentiment scores from VADER range from -1 to 1')\n",
    "print('Negative Sentiment: Less than 0')\n",
    "print('Neutral Sentiment: Equal to 0')\n",
    "print('Positive Sentiment: More than 0')\n",
    "print(f\"Average Sentiment for Agree: {average_sentiment_agree}\")\n",
    "print(f\"Average Sentiment for Disagree: {average_sentiment_disagree}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='6'>6. Word Clouds</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=['win','play','fan','supporter','like','played','won']\n",
    "# Generate word clouds for each sentiment\n",
    "generate_word_cloud(reaction_df[reaction_df['Comment_Decision']=='Agree']['Comment'], 'Agree Sentiment', stopwords)\n",
    "generate_word_cloud(reaction_df[reaction_df['Comment_Decision']=='Disagree']['Comment'], 'Disagree Sentiment', stopwords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
